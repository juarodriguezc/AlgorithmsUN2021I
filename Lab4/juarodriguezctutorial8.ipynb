{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "juarodriguezctutorial8.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y06plUUk8PjN"
      },
      "source": [
        "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fksrAl8j_Kk3"
      },
      "source": [
        "# Introduction to Financial Python\n",
        "## Confidence Interval and Hypothesis Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDtSS9bi_UQw"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySo02A6z_W_H"
      },
      "source": [
        "### Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__45bRxW_aQ3"
      },
      "source": [
        "In the last chapter we discussed random variables and random distributions. Now we are going to use the distributions we learned to test our hypothesis and also to model the financial data. When building a trading strategy, it's essential to do some research. However, you won't be able to test your idea using all the data, because it's infinity. You can only use a sample to do your experiment. That's why we need to understand the difference between population and sample, and then use confidence interval to test our hypothesis.\n",
        "\n",
        "As we mentioned before, both mean and standard deviation are point estimation, and they can be deceiving because sample means are different from population means. Financial data is generated every day now and in the future, thus even though we can use all the data available, it's still just a sample. This is why we need to use confidence interval to attempt to determine how accurate our sample mean estimation is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFumDCmW_b3I"
      },
      "source": [
        "### Confidence Interval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SLhfQ4a_e2I"
      },
      "source": [
        "**Sample Error**\n",
        "Let's use the daily return on S&P 500 index from Aug 2010 to present is our population. If we take the recent 10 daily returns to calculate the mean, will it be the same as the population mean? How about increasing the sample size to 1000?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXUxtLWb8PjU",
        "outputId": "354fd24c-1d26-4ca5-8a82-98ae1be2c54b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "qb = QuantBook()\n",
        "spy = qb.AddEquity(\"SPY\").Symbol\n",
        "\n",
        "#get SPY data from August 2010 to the present\n",
        "start_date = datetime(2010, 8, 1, 0, 0, 0)\n",
        "end_date = qb.Time\n",
        "spy_table = qb.History(spy, start_date, end_date, Resolution.Daily)\n",
        "\n",
        "spy_total = spy_table[['open','close']]\n",
        "#calculate log returns\n",
        "spy_log_return = np.log(spy_total.close).diff().dropna()\n",
        "print('Population mean:', np.mean(spy_log_return))\n",
        "print('Population standard deviation:',np.std(spy_log_return))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Population mean: 0.0005481046867835749\n",
            "Population standard deviation: 0.010787058234458887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrYsCvrQ_h32"
      },
      "source": [
        "Now let's check the recent 10 days sample and recent 1000 days sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLgTzYFv8PjW",
        "outputId": "f4f175a3-4eee-48fb-8aaf-0b06ded610bd"
      },
      "source": [
        "print('10 days sample returns:', np.mean(spy_log_return.tail(10)))\n",
        "print('10 days sample standard deviation:', np.std(spy_log_return.tail(10)))\n",
        "print('1000 days sample returns:', np.mean(spy_log_return.tail(1000)))\n",
        "print('1000 days sample standard deviation:', np.std(spy_log_return.tail(1000)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 days sample returns: 0.0008129861428401774\n",
            "10 days sample standard deviation: 0.00835988600245765\n",
            "1000 days sample returns: 0.0005970258230146666\n",
            "1000 days sample standard deviation: 0.012931517648941647\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wLjqRow_kiW"
      },
      "source": [
        "As we expected, the two samples has different means and variances.\n",
        "\n",
        "**Confidence Interval**\n",
        "\n",
        "In order to estimate the range of population mean, we define standard error of the mean as follows:\n",
        "\n",
        "$$\n",
        "SE = \\frac{\\sigma}{\\sqrt{n}}\n",
        "$$\n",
        "\n",
        "Where σ is the sample standard deviation and n is the sample size.\n",
        "\n",
        "Generally, if we want to estimate an interval of the population so that 95% of the time the interval will contain the population mean, the interval is calculated as:\n",
        "\n",
        "$$ \n",
        "(\\mu-1.96 * SE, \\mu+1.96*SE)\n",
        "$$\n",
        "\n",
        "Where μ is the sample mean and SE is the standard error.\n",
        "\n",
        "This interval is called confidence interval. We usually use 1.96 to calculate a 95% confidence interval because we assume that the sample mean follows normal distribution. We will cover this in detail later. Let's try to calculate the confidence interval using the samples above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LhLSgrS8PjW",
        "outputId": "3ec7a939-68c5-4a0f-9301-c37fb64acdee"
      },
      "source": [
        "#apply the formula above to calculate confidence interval\n",
        "bottom_1 = np.mean(spy_log_return.tail(10))-1.96*np.std(spy_log_return.tail(10))/(np.sqrt(len((spy_log_return.tail(10)))))\n",
        "upper_1 = np.mean(spy_log_return.tail(10))+1.96*np.std(spy_log_return.tail(10))/(np.sqrt(len((spy_log_return.tail(10)))))\n",
        "bottom_2 = np.mean(spy_log_return.tail(1000))-1.96*np.std(spy_log_return.tail(1000))/(np.sqrt(len((spy_log_return.tail(1000)))))\n",
        "upper_2 = np.mean(spy_log_return.tail(1000))+1.96*np.std(spy_log_return.tail(1000))/(np.sqrt(len((spy_log_return.tail(1000)))))\n",
        "#print the outcomes\n",
        "print('10 days 95% confidence inverval:', (bottom_1,upper_1))\n",
        "print('1000 days 95% confidence inverval:', (bottom_2,upper_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 days 95% confidence inverval: (-0.004368524883596551, 0.0059944971692769055)\n",
            "1000 days 95% confidence inverval: (-0.00020447794470243076, 0.0013985295907317638)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXdWDR_iAtU_"
      },
      "source": [
        "As we can see, the 95% confidence interval became much narrower if we increase the sample size from 10 to 1000. Imagine that if N goes positive infinite, then we have\n",
        "$$\n",
        "\\lim_{n\\rightarrow\\infty}{\\frac{\\sigma}{\\sqrt{n}}}\n",
        "$$\n",
        "\n",
        " The confidence interval would become a certain value, which is the sample mean!\n",
        "\n",
        "**Confidence Interval of Normal Distribution**\n",
        "\n",
        "\n",
        "Normal Distribution is so commonly used that we should be able to remember some critical values of it. Specifically, we usually use 90%, 95% and 99% as the confidence level of a confidence interval. The critical values for these three confidence levels are 1.64, 1.96, and 2.32 respectively. in other words:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQDJmc_oCqaH"
      },
      "source": [
        "$$ \n",
        "\\%90upperband = \\mu +1.64 *SE$$\n",
        "\n",
        "$$\n",
        "\\%90lowerband = \\mu +1.64 *SE\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxCDUbOnDLEn"
      },
      "source": [
        "The same for other confidence intervals. It's also important to remember the famous 'Three sigma rule' or '68-95-99.7' rule associated with normal distribution. This is used to remember the confidence level of the intervals with a width of two, four and six standard deviation. Mathematically:\n",
        "$$P(\\mu-\\sigma \\leq X \\leq \\mu + \\sigma)\\approx 0.6827 $$\n",
        "$$P(\\mu-2\\sigma \\leq X \\leq \\mu + 2\\sigma)\\approx 0.9545$$\n",
        "$$P(\\mu-3\\sigma \\leq X \\leq \\mu + 3\\sigma)\\approx 0.9973$$\n",
        "\n",
        "This can also be remembered by using the chart:\n",
        "<center><img src=\"https://cdn.quantconnect.com/tutorials/i/Tutorial08-empirical-rule.png\"></img></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORO8ur5BEjMe"
      },
      "source": [
        "**Central Limit Theory**\n",
        "As we mentioned, if we use the sample to estimate the confidence interval of the population, the 95% confidence interval is:\n",
        "$$\n",
        "(\\mu - 1.96*SE,\\mu+1.96*SE) \n",
        "$$\n",
        "\n",
        "Now you may have some sense to the number 1.96. It's the 95% critical value of a normal distribution. Does this means we assume the mean of sample follows a normal distribution? The answer is yes. This assumption is supported by central limit theorem. This theorem tells us that given a sufficiently large sample size from a population with a finite level of variance, the mean of all samples from the same population will be approximately equal to the mean of the population, and the means of the samples will be approximately normal distributed. This is the foundation of population mean confidence interval estimation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH6aN2ieEwO2"
      },
      "source": [
        "### Hypothesis testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77q00vT4E2cY"
      },
      "source": [
        "Now we can talk about hypothesis testing. Hypothesis test is essentially test your inference based on a sample. Let's use our dataset, the daily return of S&P 500 us our population. Assume that we don't know the mean of this population. I guess that the mean of this population is 0. Is my guess correct? I need to test this hypothesis with my sample. Let's start from observing our sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwlW4GgD8PjX",
        "outputId": "c887258c-865d-441c-f199-93644b48075f"
      },
      "source": [
        "mean_1000 = np.mean(spy_log_return.tail(1000))\n",
        "std_1000 = np.std(spy_log_return.tail(1000))\n",
        "mean_10 = np.mean(spy_log_return.tail(10))\n",
        "std_10 = np.std(spy_log_return.tail(10))\n",
        "s = pd.Series([mean_10,std_10,mean_1000,std_1000],index = ['mean_10', 'std_10','mean_1000','std_1000'])\n",
        "print(s)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_10      0.000813\n",
            "std_10       0.008360\n",
            "mean_1000    0.000597\n",
            "std_1000     0.012932\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyX3AzKzE4J2"
      },
      "source": [
        "We know how to calculate the confidence interval now. If I were right, i.e. the population mean is 0, then the 90% confidence interval of the sample with 1000 observations should be:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnWWtXam8PjX",
        "outputId": "3ee00578-3be3-43ad-e517-b741d8489362"
      },
      "source": [
        "bottom = 0 - 1.64*std_1000/np.sqrt(1000)\n",
        "upper = 0 + 1.64*std_1000/np.sqrt(1000)\n",
        "print((bottom, upper))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-0.0006706460097224693, 0.0006706460097224693)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpPpHAnuE6Sf"
      },
      "source": [
        "Our mean of the sample is out of the 90% confidence interval. This means on a 90% confidence level, we can claim that the mean of our population is not 0. In other word, we rejected the hypothesis that the daily return on S&P500 from aug 2010 is zero. Can we claim that with 95% confidence level?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L48vf6JY8PjY",
        "outputId": "56c1301c-6bf4-4eb3-83a2-5843229fcd80"
      },
      "source": [
        "bottom = 0 - 1.96*std_1000/np.sqrt(1000)\n",
        "upper = 0 + 1.96*std_1000/np.sqrt(1000)\n",
        "print((bottom, upper))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-0.0008015037677170973, 0.0008015037677170973)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLIzuExsE9zn"
      },
      "source": [
        "This time the sample mean is within the confidence interval. Thus we can't reject my hypothesis. In other words, we can't claim with 95% confidence level that the mean return is positive. Even though we can claim it with 90% confidence level. We have actually already finished a hypothesis testing above! In general, we have null hypothesis H0 and alternative hypothesis. They are usually in the following forms:\n",
        "$$ H_{0} : \\bar{\\mu} = 0$$\n",
        "$$ H_{0} : \\bar{\\mu} \\neq 0$$\n",
        "\n",
        "If the tested value is outside the confidence interval, we reject the null hypothesis, or accept the alternative hypothesis; If the tested value is within the confidence interval, we can't reject the null hypothesis. Although the hypothesis testing method we used above is straightforward, it's not so convenient to implement. Instead, we reverse the process to calculate the critical value, or Z-score. Z-score is defined as:\n",
        "\n",
        "$$\n",
        "Z=\\frac{X-\\mu}{\\frac{\\sigma}{\\sqrt{n}}}\n",
        "$$\n",
        "\n",
        "Let's calculate the Z score from our sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyzhWGHX8PjY",
        "outputId": "4acf6185-44d5-4508-a2ba-e9eed2e81c1e"
      },
      "source": [
        "print(np.sqrt(1000)*(mean_1000 - 0)/std_1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.4599689486697156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_ZdX9NAFjSW"
      },
      "source": [
        "We know that the critical value for the 90% confidence level is 1.64 and that for the 95% confidence level is 95%. The higher the Z score is, the further the tested value is from the hypothesized value(which is 0 in this example). Thus with 90% confidence level, we are far away enough from zero and we reject the null hypothesis. However with 95% confidence level, we are not far away enough from zero, so we can't reject the null hypothesis. One reason of doing in this way is that we can know how wide our confidence interval is. In our example, the z-score is 1.8488. We can know the width is the confidence interval referring to a normal distribution table. Of course we can do this in Python:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcG1hyVJ8PjZ",
        "outputId": "6e4b0ff4-6e72-440f-f65d-5b480a5e51d1"
      },
      "source": [
        "import scipy.stats as st\n",
        "print((1 - st.norm.cdf(1.9488)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02565965688799665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3C6qrpBFnMn"
      },
      "source": [
        "It's worth noting that st.norm.cdf will return the probability that a value take from the distribution is less than our tested value. In other words, 1 - st.norm.cdf(1.9488) will return the probability that the value is greater than our tested value, which is 0.025659 in this example. This calculated number is called p-value. If our confidence level our confidence interval is 95%, then we have 2.5% on the left side and 2.5% on the right side. This is called two-tail test. If our null hypothesis is μ=0, we are conducting two-tail test because the tested sample mean can be either positive enough or negative enough to reject the null hypothesis. We can see it from the chart:\n",
        "\n",
        "<center><img src=\"https://cdn.quantconnect.com/tutorials/i/Tutorial08-confidence-interval.jpg\"></img></center>\n",
        "\n",
        "If we use 95% confidence interval, we need a p-value less than 0.025 to reject the null hypothesis. However, now our p-value is 0.025659, which is greater than 0.025, thus we can't reject the null hypothesis. It's obviously less than 0.05, so we can still reject the null hypothesis with 90% confidence level. Now let's test the hypothesis that population mean = 0 again with a large sample, which has 1200 observations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujj1WClG8PjZ",
        "outputId": "92f94f89-7e7d-4d3b-e78a-388bc11868b7"
      },
      "source": [
        "mean_1200 = np.mean(spy_log_return.tail(1200))\n",
        "std_1200 = np.std(spy_log_return.tail(1200))\n",
        "z_score = np.sqrt(1200)*(mean_1200 - 0)/std_1200\n",
        "print('z-score = ',z_score)\n",
        "p_value = (1 - st.norm.cdf(z_score))\n",
        "print('p_value = ',p_value)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z-score =  1.7530712831508348\n",
            "p_value =  0.039794886034644095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adkIpDmPFwEu"
      },
      "source": [
        "Using the a larger sample, now we can reject the null hypothesis with a higher confidence interval! our p-value is 0.0105, and it's a two-tail test, so our confidence level of the interval is 1-(0.0105*2) = 0.979. We can say at most with 97.9% confidence interval, we can claim that the population mean is not zero. We already know that the population mean is not 0. As our sample size increasing, the accurate rate of our hypothesis goes up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qqx0DRfEFymf"
      },
      "source": [
        "### Mi ejemplo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAS3nxU98Pja",
        "outputId": "6f0dc844-dc72-40f0-8d61-e4b2e2b53182"
      },
      "source": [
        "qb2 = QuantBook()\n",
        "aapl = qb2.AddEquity(\"AAPL\").Symbol\n",
        "#Se guardan datos desde el lanzamiento del primer iphone\n",
        "start_date2 = datetime(2007, 6, 29, 0, 0, 0)\n",
        "end_date2 = qb2.Time\n",
        "aapl_table = qb2.History(aapl, start_date, end_date, Resolution.Daily)\n",
        "\n",
        "aapl_total = aapl_table[['open','close']]\n",
        "aapl_log_return = np.log(aapl_total.close).diff().dropna()\n",
        "print('Population mean:', np.mean(aapl_log_return))\n",
        "print('Population standard deviation:',np.std(aapl_log_return))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Population mean: 0.001011261840353075\n",
            "Population standard deviation: 0.017848654797024178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKHMX7GZ8Pja",
        "outputId": "6678622a-6f59-4a90-a5da-b05680f63de4"
      },
      "source": [
        "print('10 days sample returns:', np.mean(aapl_log_return.tail(10)))\n",
        "print('10 days sample standard deviation:', np.std(aapl_log_return.tail(10)))\n",
        "print('1000 days sample returns:', np.mean(aapl_log_return.tail(1000)))\n",
        "print('1000 days sample standard deviation:', np.std(aapl_log_return.tail(1000)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 days sample returns: 0.00014861297319077594\n",
            "10 days sample standard deviation: 0.01809897239385377\n",
            "1000 days sample returns: 0.0012654006104160236\n",
            "1000 days sample standard deviation: 0.020515081561995697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmM3mckr8Pjb",
        "outputId": "54204a6f-1c4f-43a4-e78e-999399b87bfb"
      },
      "source": [
        "#apply the formula above to calculate confidence interval\n",
        "bottom_1_aapl = np.mean(aapl_log_return.tail(10))-1.96*np.std(aapl_log_return.tail(10))/(np.sqrt(len((aapl_log_return.tail(10)))))\n",
        "upper_1_aapl = np.mean(aapl_log_return.tail(10))+1.96*np.std(aapl_log_return.tail(10))/(np.sqrt(len((aapl_log_return.tail(10)))))\n",
        "bottom_2_aapl = np.mean(aapl_log_return.tail(1000))-1.96*np.std(aapl_log_return.tail(1000))/(np.sqrt(len((aapl_log_return.tail(1000)))))\n",
        "upper_2_aapl = np.mean(aapl_log_return.tail(1000))+1.96*np.std(aapl_log_return.tail(1000))/(np.sqrt(len((aapl_log_return.tail(1000)))))\n",
        "#print the outcomes\n",
        "print('10 days 95% confidence inverval:', (bottom_1_aapl,upper_1_aapl))\n",
        "print('1000 days 95% confidence inverval:', (bottom_2_aapl,upper_2_aapl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 days 95% confidence inverval: (-0.011069246337134471, 0.011366472283516022)\n",
            "1000 days 95% confidence inverval: (-6.137318336588236e-06, 0.0025369385391686354)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gK5hFj38Pjb",
        "outputId": "d8b7c9d9-0877-4460-f0c3-a3f1f1ea853b"
      },
      "source": [
        "mean_1000_aapl = np.mean(aapl_log_return.tail(1000))\n",
        "std_1000_aapl = np.std(aapl_log_return.tail(1000))\n",
        "mean_10_aapl = np.mean(aapl_log_return.tail(10))\n",
        "std_10_aapl = np.std(aapl_log_return.tail(10))\n",
        "s_aapl = pd.Series([mean_10_aapl,std_10_aapl,mean_1000_aapl,std_1000_aapl],index = ['mean_10', 'std_10','mean_1000','std_1000'])\n",
        "print(s_aapl)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean_10      0.000149\n",
            "std_10       0.018099\n",
            "mean_1000    0.001265\n",
            "std_1000     0.020515\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JcqrXU38Pjb",
        "outputId": "73af09c3-3524-40aa-f19d-ebd5708108eb"
      },
      "source": [
        "bottom_aapl = 0 - 1.64*std_1000_aapl/np.sqrt(1000)\n",
        "upper_aapl = 0 + 1.64*std_1000_aapl/np.sqrt(1000)\n",
        "print((bottom_aapl, upper_aapl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-0.001063939899568512, 0.001063939899568512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPf1JbuZ8Pjc",
        "outputId": "6b699df9-f459-4591-8b19-6d65824d04da"
      },
      "source": [
        "bottom_aapl = 0 - 1.96*std_1000_aapl/np.sqrt(1000)\n",
        "upper_aapl = 0 + 1.96*std_1000_aapl/np.sqrt(1000)\n",
        "print((bottom_aapl, upper_aapl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(-0.0012715379287526118, 0.0012715379287526118)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LRkcxRg8Pjc",
        "outputId": "0391dd4b-a279-4fdc-b99d-baf944eeb7b2"
      },
      "source": [
        "print(np.sqrt(1000)*(mean_1000_aapl - 0)/std_1000_aapl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.9505396892474032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg3wbBKB8Pjc",
        "outputId": "aca7cdf1-384d-448e-b81f-f59e140722fa"
      },
      "source": [
        "import scipy.stats as st\n",
        "print((1 - st.norm.cdf(1.9488)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02565965688799665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwMvLEx78Pjc",
        "outputId": "22c3b39d-3f44-4315-aa6c-43cefeb27335"
      },
      "source": [
        "mean_1200_aapl = np.mean(aapl_log_return.tail(1200))\n",
        "std_1200_aapl = np.std(aapl_log_return.tail(1200))\n",
        "z_score_aapl = np.sqrt(1200)*(mean_1200_aapl - 0)/std_1200_aapl\n",
        "print('z-score = ',z_score_aapl)\n",
        "p_value_aapl = (1 - st.norm.cdf(z_score_aapl))\n",
        "print('p_value = ',p_value_aapl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z-score =  2.537215239096944\n",
            "p_value =  0.005586911551146101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jue67lozF1vX"
      },
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmhd5IK8F6bn"
      },
      "source": [
        "In this chapter we introduced confidence interval, especially that for the normal distribution, and hypothesis test. Now we know how to test our idea rigorously. Normal distribution and it's confidence interval can be applied to many quantitative finance theories, we will see it frequently in our following tutorials."
      ]
    }
  ]
}