{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "juarodriguezctutorial5.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXE6ZxXkb5XI"
      },
      "source": [
        "# Introduction to Financial Python\n",
        "Pandas-Resampling and DataFrame\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHFA31Mqb_LZ"
      },
      "source": [
        "## Introduction\n",
        "In the last chapter we had a glimpse of Pandas. In this chapter we will learn about resampling methods and the DataFrame object, which is a powerful tool for financial data analysis.\n",
        "## Fetching Data\n",
        "Fetching Data\n",
        "Here we use the Quandl API to retrieve data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lVbt9xiH-ps",
        "outputId": "fba2e085-cd18-4b70-cf62-8fe7e199f655"
      },
      "source": [
        "! pip install quandl"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: quandl in /usr/local/lib/python3.7/dist-packages (3.6.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from quandl) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from quandl) (1.15.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from quandl) (8.7.0)\n",
            "Requirement already satisfied: inflection>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from quandl) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from quandl) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from quandl) (2.23.0)\n",
            "Requirement already satisfied: pandas>=0.14 in /usr/local/lib/python3.7/dist-packages (from quandl) (1.1.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->quandl) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->quandl) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.7.0->quandl) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.14->quandl) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLjtSQOMboK-"
      },
      "source": [
        "import quandl\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywjXiZeNIkVr"
      },
      "source": [
        "We will create a Series named \"aapl\" whose values are Apple's daily closing prices, which are of course indexed by dates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaEAexCIboLE"
      },
      "source": [
        "quandl.ApiConfig.api_key = 'M3nyR86csNzuacBunen8'\n",
        "aapl_table = quandl.get('WIKI/AAPL')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0U3wIyHIl6D"
      },
      "source": [
        "Recall that we can fetch a specific data point using series['yyyy-mm-dd']. We can also fetch the data in a specific month using series['yyyy-mm']."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObNiPaxVboLE"
      },
      "source": [
        "aapl = aapl_table['Adj. Close']['2017']"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUPymSgtboLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf75da2-d504-4ff5-d36a-70d68a0be582"
      },
      "source": [
        "print(aapl)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-03    114.715378\n",
            "2017-01-04    114.586983\n",
            "2017-01-05    115.169696\n",
            "2017-01-06    116.453639\n",
            "2017-01-09    117.520300\n",
            "                 ...    \n",
            "2017-12-22    175.010000\n",
            "2017-12-26    170.570000\n",
            "2017-12-27    170.600000\n",
            "2017-12-28    171.080000\n",
            "2017-12-29    169.230000\n",
            "Name: Adj. Close, Length: 249, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHA7xBWJIpGS"
      },
      "source": [
        "Or in several consecutive months:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM7E5CaFboLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ffd4764-8283-41f0-a7f2-41430a843b55"
      },
      "source": [
        "print(aapl['2017-3'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-03-01    138.657681\n",
            "2017-03-02    137.834404\n",
            "2017-03-03    138.647762\n",
            "2017-03-06    138.211326\n",
            "2017-03-07    138.389868\n",
            "2017-03-08    137.874080\n",
            "2017-03-09    137.556672\n",
            "2017-03-10    138.012946\n",
            "2017-03-13    138.072460\n",
            "2017-03-14    137.864161\n",
            "2017-03-15    139.322254\n",
            "2017-03-16    139.550391\n",
            "2017-03-17    138.856061\n",
            "2017-03-20    140.314154\n",
            "2017-03-21    138.707276\n",
            "2017-03-22    140.274478\n",
            "2017-03-23    139.778528\n",
            "2017-03-24    139.500796\n",
            "2017-03-27    139.738852\n",
            "2017-03-28    142.635200\n",
            "2017-03-29    142.952608\n",
            "2017-03-30    142.764147\n",
            "2017-03-31    142.496334\n",
            "Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNmn8Go9boLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c56ff4-6d26-428d-9636-d7d21b191289"
      },
      "source": [
        "aapl['2017-2':'2017-4']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2017-02-01    127.159749\n",
              "2017-02-02    126.942467\n",
              "2017-02-03    127.485673\n",
              "2017-02-06    128.680728\n",
              "2017-02-07    129.905412\n",
              "                 ...    \n",
              "2017-04-24    142.476496\n",
              "2017-04-25    143.369205\n",
              "2017-04-26    142.487208\n",
              "2017-04-27    142.625281\n",
              "2017-04-28    142.486415\n",
              "Name: Adj. Close, Length: 61, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqWRX1yBIrwN"
      },
      "source": [
        ".head(N) and .tail(N) are methods for quickly accessing the first or last N elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaLTXnw9boLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6774af-43ec-466e-bb7a-451b08d5e00f"
      },
      "source": [
        "print(aapl.head(5))\n",
        "print(aapl.tail(10))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-03    114.715378\n",
            "2017-01-04    114.586983\n",
            "2017-01-05    115.169696\n",
            "2017-01-06    116.453639\n",
            "2017-01-09    117.520300\n",
            "Name: Adj. Close, dtype: float64\n",
            "Date\n",
            "2017-12-15    173.87\n",
            "2017-12-18    176.42\n",
            "2017-12-19    174.54\n",
            "2017-12-20    174.35\n",
            "2017-12-21    175.01\n",
            "2017-12-22    175.01\n",
            "2017-12-26    170.57\n",
            "2017-12-27    170.60\n",
            "2017-12-28    171.08\n",
            "2017-12-29    169.23\n",
            "Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqd4U0ZcIvz7"
      },
      "source": [
        "## Resampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgCLUN_8Iudk"
      },
      "source": [
        "\n",
        "series.resample(freq) is a class called \"DatetimeIndexResampler\" which groups data in a Series object into regular time intervals. The argument \"freq\" determines the length of each interval.\n",
        "\n",
        "series.resample.mean() is a complete statement that groups data into intervals, and then compute the mean of each interval. For example, if we want to aggregate the daily data into monthly data by mean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F1_4gooboLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a67787f3-d955-4218-d33d-0ed6ee8f0e19"
      },
      "source": [
        "by_month = aapl.resample('M').mean()\n",
        "print(by_month)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-31    118.093136\n",
            "2017-02-28    132.456268\n",
            "2017-03-31    139.478802\n",
            "2017-04-30    141.728436\n",
            "2017-05-31    151.386305\n",
            "2017-06-30    147.233064\n",
            "2017-07-31    147.706190\n",
            "2017-08-31    158.856375\n",
            "2017-09-30    157.606500\n",
            "2017-10-31    157.811627\n",
            "2017-11-30    172.214500\n",
            "2017-12-31    171.893100\n",
            "Freq: M, Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq4VWG5AIyly"
      },
      "source": [
        "We can also aggregate the data by week:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnlpyrVxboLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd63c1aa-e6d3-4a9b-ea30-14673e57701e"
      },
      "source": [
        "by_week = aapl.resample('W').mean()\n",
        "print(by_week.head())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-08    115.231424\n",
            "2017-01-15    117.755360\n",
            "2017-01-22    118.461035\n",
            "2017-01-29    119.667448\n",
            "2017-02-05    124.313346\n",
            "Freq: W-SUN, Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTtrMgDwI1zE"
      },
      "source": [
        "We can choose almost any frequency by using the format 'nf', where 'n' is an integer and 'f' is M for month, W for week and D for day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCHbMquSboLH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dae3a18e-7ee2-4632-f447-ccd00fee5f14"
      },
      "source": [
        "aapl.resample('M').max()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2017-01-31    120.443739\n",
              "2017-02-28    135.999390\n",
              "2017-03-31    142.952608\n",
              "2017-04-30    143.597342\n",
              "2017-05-31    155.469192\n",
              "2017-06-30    154.821818\n",
              "2017-07-31    152.839860\n",
              "2017-08-31    164.000000\n",
              "2017-09-30    164.050000\n",
              "2017-10-31    169.040000\n",
              "2017-11-30    175.880000\n",
              "2017-12-31    176.420000\n",
              "Freq: M, Name: Adj. Close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU3IPfh1boLH"
      },
      "source": [
        "three_day = aapl.resample('3D').mean()\n",
        "two_week = aapl.resample('2W').mean()\n",
        "two_month = aapl.resample('2M').mean()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCjmiXoXI5eq"
      },
      "source": [
        "Besides the mean() method, other methods can also be used with the resampler:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9I0CY4HboLH"
      },
      "source": [
        "std = aapl.resample('W').std()\n",
        "max = aapl.resample('W').max()\n",
        "min = aapl.resample('W').min()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AliPkSaI6ou"
      },
      "source": [
        "Often we want to calculate monthly returns of a stock, based on prices on the last day of each month. To fetch those prices, we use the series.resample.agg() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPwhppPwboLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda6ac06-72c3-4691-87ee-6fd3efd81ff9"
      },
      "source": [
        "last_day = aapl.resample('M').agg(lambda x: x[-1])\n",
        "print(last_day)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-31    119.851150\n",
            "2017-02-28    135.880362\n",
            "2017-03-31    142.496334\n",
            "2017-04-30    142.486415\n",
            "2017-05-31    152.142689\n",
            "2017-06-30    143.438008\n",
            "2017-07-31    148.248489\n",
            "2017-08-31    164.000000\n",
            "2017-09-30    154.120000\n",
            "2017-10-31    169.040000\n",
            "2017-11-30    171.850000\n",
            "2017-12-31    169.230000\n",
            "Freq: M, Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luXBflv2I9Wy"
      },
      "source": [
        "Or directly calculate the monthly rates of return using the data for the first day and the last day:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6ECL1WdboLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dc95176-d762-4a89-ab7e-5e826c7e088c"
      },
      "source": [
        "monthly_return = aapl.resample('M').agg(lambda x: x[-1]/x[1] - 1)\n",
        "print(monthly_return)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-31    0.045940\n",
            "2017-02-28    0.070409\n",
            "2017-03-31    0.033823\n",
            "2017-04-30   -0.007736\n",
            "2017-05-31    0.039829\n",
            "2017-06-30   -0.073528\n",
            "2017-07-31    0.033035\n",
            "2017-08-31    0.047890\n",
            "2017-09-30   -0.049112\n",
            "2017-10-31    0.094252\n",
            "2017-11-30    0.022247\n",
            "2017-12-31   -0.003357\n",
            "Freq: M, Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPx3mdcLJErx"
      },
      "source": [
        "Series object also provides us some convenient methods to do some quick calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSabwv10boLI"
      },
      "source": [
        "by_week = aapl.resample('W').mean()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j-RUP8LboLI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfae9012-9724-46eb-bd69-50d21b9b6692"
      },
      "source": [
        "twomon = aapl.resample('2M').std()\n",
        "twomon"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2017-01-31    1.781512\n",
              "2017-03-31    4.323834\n",
              "2017-05-31    5.454495\n",
              "2017-07-31    3.865333\n",
              "2017-09-30    3.634223\n",
              "2017-11-30    8.011704\n",
              "2018-01-31    2.291229\n",
              "Freq: 2M, Name: Adj. Close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ08u_VeboLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb864e6-17a1-43b1-954a-aa8bf9b0599d"
      },
      "source": [
        "last_day = aapl.resample('M').agg(lambda x: x[-1])\n",
        "last_day"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2017-01-31    119.851150\n",
              "2017-02-28    135.880362\n",
              "2017-03-31    142.496334\n",
              "2017-04-30    142.486415\n",
              "2017-05-31    152.142689\n",
              "2017-06-30    143.438008\n",
              "2017-07-31    148.248489\n",
              "2017-08-31    164.000000\n",
              "2017-09-30    154.120000\n",
              "2017-10-31    169.040000\n",
              "2017-11-30    171.850000\n",
              "2017-12-31    169.230000\n",
              "Freq: M, Name: Adj. Close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBKm2OFgboLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737f581a-b6ce-4cd0-dae5-4e9fbd6556e5"
      },
      "source": [
        "monthly_return = aapl.resample('M').agg(lambda x: x[-1]/x[1] - 1)\n",
        "monthly_return"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2017-01-31    0.045940\n",
              "2017-02-28    0.070409\n",
              "2017-03-31    0.033823\n",
              "2017-04-30   -0.007736\n",
              "2017-05-31    0.039829\n",
              "2017-06-30   -0.073528\n",
              "2017-07-31    0.033035\n",
              "2017-08-31    0.047890\n",
              "2017-09-30   -0.049112\n",
              "2017-10-31    0.094252\n",
              "2017-11-30    0.022247\n",
              "2017-12-31   -0.003357\n",
              "Freq: M, Name: Adj. Close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-hvdwaoboLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3cebe82-6a68-4d64-e88d-77e144cff3e3"
      },
      "source": [
        "print(monthly_return.mean())\n",
        "print(monthly_return.std())\n",
        "print(monthly_return.max())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02114094011940022\n",
            "0.04775652864223314\n",
            "0.09425168306576914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zf173erJNC1"
      },
      "source": [
        "Another two methods frequently used on Series are .diff() and .pct_change(). The former calculates the difference between consecutive elements, and the latter calculates the percentage change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEpxBNLpboLJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afd3056d-272e-4329-941d-7888f4e9f7e7"
      },
      "source": [
        "print(last_day.diff())\n",
        "print(last_day.pct_change())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-31          NaN\n",
            "2017-02-28    16.029211\n",
            "2017-03-31     6.615972\n",
            "2017-04-30    -0.009919\n",
            "2017-05-31     9.656274\n",
            "2017-06-30    -8.704681\n",
            "2017-07-31     4.810482\n",
            "2017-08-31    15.751511\n",
            "2017-09-30    -9.880000\n",
            "2017-10-31    14.920000\n",
            "2017-11-30     2.810000\n",
            "2017-12-31    -2.620000\n",
            "Freq: M, Name: Adj. Close, dtype: float64\n",
            "Date\n",
            "2017-01-31         NaN\n",
            "2017-02-28    0.133743\n",
            "2017-03-31    0.048690\n",
            "2017-04-30   -0.000070\n",
            "2017-05-31    0.067770\n",
            "2017-06-30   -0.057214\n",
            "2017-07-31    0.033537\n",
            "2017-08-31    0.106251\n",
            "2017-09-30   -0.060244\n",
            "2017-10-31    0.096808\n",
            "2017-11-30    0.016623\n",
            "2017-12-31   -0.015246\n",
            "Freq: M, Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd9mzh1zJUDb"
      },
      "source": [
        "Notice that we induced a NaN value while calculating percentage changes i.e. returns.\n",
        "\n",
        "When dealing with NaN values, we usually either removing the data point or fill it with a specific value. Here we fill it with 0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQmKxGKbboLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63614cbb-d64d-48e4-cc61-0a646c614c9f"
      },
      "source": [
        "print(aapl.describe())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    249.000000\n",
            "mean     149.815713\n",
            "std       15.065681\n",
            "min      114.586983\n",
            "25%      140.651400\n",
            "50%      151.890000\n",
            "75%      159.780000\n",
            "max      176.420000\n",
            "Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVolF6hqJVdi"
      },
      "source": [
        "Alternatively, we can fill a NaN with the next fitted value. This is called 'backward fill', or 'bfill' in short:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hwgm-GFboLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68089c86-ef73-4346-b859-42bf6e0b14a3"
      },
      "source": [
        "daily_return = last_day.pct_change()\n",
        "print(daily_return.fillna(0))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-31    0.000000\n",
            "2017-02-28    0.133743\n",
            "2017-03-31    0.048690\n",
            "2017-04-30   -0.000070\n",
            "2017-05-31    0.067770\n",
            "2017-06-30   -0.057214\n",
            "2017-07-31    0.033537\n",
            "2017-08-31    0.106251\n",
            "2017-09-30   -0.060244\n",
            "2017-10-31    0.096808\n",
            "2017-11-30    0.016623\n",
            "2017-12-31   -0.015246\n",
            "Freq: M, Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6GGxObxJXCk"
      },
      "source": [
        "As expected, since there is a 'backward fill' method, there must be a 'forward fill' method, or 'ffill' in short. However we can't use it here because the NaN is the first value.\n",
        "\n",
        "We can also simply remove NaN values by .dropna()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vSiszmrboLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6b94a6-41a4-41e9-aea7-8ae60daa4b88"
      },
      "source": [
        "daily_return = last_day.pct_change()\n",
        "print(daily_return.fillna(method = 'bfill'))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2017-01-31    0.133743\n",
            "2017-02-28    0.133743\n",
            "2017-03-31    0.048690\n",
            "2017-04-30   -0.000070\n",
            "2017-05-31    0.067770\n",
            "2017-06-30   -0.057214\n",
            "2017-07-31    0.033537\n",
            "2017-08-31    0.106251\n",
            "2017-09-30   -0.060244\n",
            "2017-10-31    0.096808\n",
            "2017-11-30    0.016623\n",
            "2017-12-31   -0.015246\n",
            "Freq: M, Name: Adj. Close, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWQ1Y7epboLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa70f2b6-f620-4d5d-919e-2c0811def41f"
      },
      "source": [
        "daily_return = last_day.pct_change()\n",
        "daily_return.dropna()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date\n",
              "2017-02-28    0.133743\n",
              "2017-03-31    0.048690\n",
              "2017-04-30   -0.000070\n",
              "2017-05-31    0.067770\n",
              "2017-06-30   -0.057214\n",
              "2017-07-31    0.033537\n",
              "2017-08-31    0.106251\n",
              "2017-09-30   -0.060244\n",
              "2017-10-31    0.096808\n",
              "2017-11-30    0.016623\n",
              "2017-12-31   -0.015246\n",
              "Freq: M, Name: Adj. Close, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2VLk-erJYnY"
      },
      "source": [
        "## DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoygSxyxJaNy"
      },
      "source": [
        "The DataFrame is the most commonly used data structure in Pandas. It is essentially a table, just like an Excel spreadsheet.\n",
        "\n",
        "More precisely, a DataFrame is a collection of Series objects, each of which may contain different data types. A DataFrame can be created from various data types: dictionary, 2-D numpy.ndarray, a Series or another DataFrame.\n",
        "\n",
        "Create DataFrames\n",
        "The most common method of creating a DataFrame is passing a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibIT47PCboLL"
      },
      "source": [
        "# aapl.resample('M').agg(lambda x: max(x) - min(x))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DM7obcrOboLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4effb284-c528-4057-c209-a1481905cff4"
      },
      "source": [
        "dict = {'AAPL': [143.5, 144.09, 142.73, 144.18, 143.77],'GOOG':[898.7, 911.71, 906.69, 918.59, 926.99],\n",
        "        'IBM':[155.58, 153.67, 152.36, 152.94, 153.49]}\n",
        "data_index = pd.date_range('2017-07-03',periods = 5, freq = 'D')\n",
        "df = pd.DataFrame(dict, index = data_index)\n",
        "print(df)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              AAPL    GOOG     IBM\n",
            "2017-07-03  143.50  898.70  155.58\n",
            "2017-07-04  144.09  911.71  153.67\n",
            "2017-07-05  142.73  906.69  152.36\n",
            "2017-07-06  144.18  918.59  152.94\n",
            "2017-07-07  143.77  926.99  153.49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrKHOZHTboLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73f1b3c8-2677-43c8-edab-73d863df998e"
      },
      "source": [
        "s1 = pd.Series([143.5, 144.09, 142.73, 144.18, 143.77], name = 'AAPL')\n",
        "s2 = pd.Series([898.7, 911.71, 906.69, 918.59, 926.99], name = 'GOOG')\n",
        "data_frame = pd.concat([s1,s2], axis = 1)\n",
        "print(data_frame)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     AAPL    GOOG\n",
            "0  143.50  898.70\n",
            "1  144.09  911.71\n",
            "2  142.73  906.69\n",
            "3  144.18  918.59\n",
            "4  143.77  926.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuau6gb7boLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7a0094-e8e6-4726-e84d-20fdc9e5d0b8"
      },
      "source": [
        "print(df.columns)\n",
        "print(df.AAPL)\n",
        "print(df['GOOG'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['AAPL', 'GOOG', 'IBM'], dtype='object')\n",
            "2017-07-03    143.50\n",
            "2017-07-04    144.09\n",
            "2017-07-05    142.73\n",
            "2017-07-06    144.18\n",
            "2017-07-07    143.77\n",
            "Freq: D, Name: AAPL, dtype: float64\n",
            "2017-07-03    898.70\n",
            "2017-07-04    911.71\n",
            "2017-07-05    906.69\n",
            "2017-07-06    918.59\n",
            "2017-07-07    926.99\n",
            "Freq: D, Name: GOOG, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxypUb02Jhg6"
      },
      "source": [
        "**Manipulating DataFrames**\n",
        "\n",
        "\n",
        "We can fetch values in a DataFrame by columns and index. Each column in a DataFrame is essentially a Pandas Series. We can fetch a column by square brackets: df['column_name']\n",
        "\n",
        "If a column name contains no spaces, then we can also use df.column_name to fetch a column:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_PndHHtboLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd28dd6-7605-424b-b534-ab5487f07adf"
      },
      "source": [
        "df = aapl_table\n",
        "print(df.Close.tail(5))\n",
        "print(df['Adj. Volume'].tail(5))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2018-03-21    171.270\n",
            "2018-03-22    168.845\n",
            "2018-03-23    164.940\n",
            "2018-03-26    172.770\n",
            "2018-03-27    168.340\n",
            "Name: Close, dtype: float64\n",
            "Date\n",
            "2018-03-21    35247358.0\n",
            "2018-03-22    41051076.0\n",
            "2018-03-23    40248954.0\n",
            "2018-03-26    36272617.0\n",
            "2018-03-27    38962839.0\n",
            "Name: Adj. Volume, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYhnuHjIJxFS"
      },
      "source": [
        "All the methods we applied to a Series index such as iloc[], loc[] and resampling methods, can also be applied to a DataFrame:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab3F6lDoboLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe683400-0dd0-4af0-d1a5-b9e6b086582c"
      },
      "source": [
        "aapl_2016 = df['2016']\n",
        "aapl_month = aapl_2016.resample('M').agg(lambda x: x[-1])\n",
        "print(aapl_month)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low  ...    Adj. Low  Adj. Close  Adj. Volume\n",
            "Date                                  ...                                     \n",
            "2016-01-31   94.79   97.3400   94.35  ...   91.156128   94.044912   64416504.0\n",
            "2016-02-29   96.86   98.2300   96.65  ...   93.880927   93.919781   35216277.0\n",
            "2016-03-31  109.72  109.9000  108.88  ...  105.760531  105.867380   25888449.0\n",
            "2016-04-30   93.99   94.7200   92.51  ...   89.859540   91.054300   68531478.0\n",
            "2016-05-31   99.60  100.4000   98.82  ...   96.575559   97.591939   42307212.0\n",
            "2016-06-30   94.44   95.7700   94.30  ...   92.158220   93.428693   35836356.0\n",
            "2016-07-31  104.19  104.5500  103.68  ...  101.325177  101.843140   27733688.0\n",
            "2016-08-31  105.66  106.5699  105.64  ...  103.796505  104.248477   29662406.0\n",
            "2016-09-30  112.46  113.3700  111.80  ...  109.849008  111.077195   36379106.0\n",
            "2016-10-31  113.65  114.2300  113.20  ...  111.224577  111.558644   26419398.0\n",
            "2016-11-30  111.56  112.2000  110.27  ...  108.908004  109.154917   36162258.0\n",
            "2016-12-31  116.65  117.2000  115.43  ...  114.004271  114.389454   30586265.0\n",
            "\n",
            "[12 rows x 12 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5-qEVQOJzoC"
      },
      "source": [
        "We may select certain columns of a DataFrame using their names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPBkpTRAboLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2baa226d-7eee-42fe-9ab7-dc3a319e214d"
      },
      "source": [
        "aapl_bar = aapl_month[['Open', 'High', 'Low', 'Close']]\n",
        "print(aapl_bar)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close\n",
            "Date                                        \n",
            "2016-01-31   94.79   97.3400   94.35   97.34\n",
            "2016-02-29   96.86   98.2300   96.65   96.69\n",
            "2016-03-31  109.72  109.9000  108.88  108.99\n",
            "2016-04-30   93.99   94.7200   92.51   93.74\n",
            "2016-05-31   99.60  100.4000   98.82   99.86\n",
            "2016-06-30   94.44   95.7700   94.30   95.60\n",
            "2016-07-31  104.19  104.5500  103.68  104.21\n",
            "2016-08-31  105.66  106.5699  105.64  106.10\n",
            "2016-09-30  112.46  113.3700  111.80  113.05\n",
            "2016-10-31  113.65  114.2300  113.20  113.54\n",
            "2016-11-30  111.56  112.2000  110.27  110.52\n",
            "2016-12-31  116.65  117.2000  115.43  115.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyVWxyrBJ05S"
      },
      "source": [
        "We can even specify both rows and columns using loc[]. The row indices and column names are separated by a comma:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDFenAEuboLM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b948c610-6cd5-49a7-90a8-53afd6f02e21"
      },
      "source": [
        "print(aapl_month.loc['2016-03':'2016-06',['Open', 'High', 'Low', 'Close']])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open    High     Low   Close\n",
            "Date                                      \n",
            "2016-03-31  109.72  109.90  108.88  108.99\n",
            "2016-04-30   93.99   94.72   92.51   93.74\n",
            "2016-05-31   99.60  100.40   98.82   99.86\n",
            "2016-06-30   94.44   95.77   94.30   95.60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgulpVZTJ27k"
      },
      "source": [
        "The subset methods in DataFrame is quite useful. By writing logical statements in square brackets, we can make customized subsets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BIUr5utboLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78a6109-9ae4-4d8b-b2de-9b6de36ec6b7"
      },
      "source": [
        "above = aapl_bar[aapl_bar.Close > np.mean(aapl_bar.Close)]\n",
        "print(above)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close\n",
            "Date                                        \n",
            "2016-03-31  109.72  109.9000  108.88  108.99\n",
            "2016-08-31  105.66  106.5699  105.64  106.10\n",
            "2016-09-30  112.46  113.3700  111.80  113.05\n",
            "2016-10-31  113.65  114.2300  113.20  113.54\n",
            "2016-11-30  111.56  112.2000  110.27  110.52\n",
            "2016-12-31  116.65  117.2000  115.43  115.82\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZyWPul0uJ5aM"
      },
      "source": [
        "**Data Validation**\n",
        "\n",
        "As mentioned, all methods that apply to a Series can also be applied to a DataFrame. Here we add a new column to an existing DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSx3OP5uboLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bda0a694-14fd-4977-db4d-d59835edfa95"
      },
      "source": [
        "aapl_bar['rate_return'] = aapl_bar.Close.pct_change()\n",
        "print(aapl_bar)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close  rate_return\n",
            "Date                                                     \n",
            "2016-01-31   94.79   97.3400   94.35   97.34          NaN\n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34VJ9I3ZJ8uJ"
      },
      "source": [
        "Here the calculation introduced a NaN value. If the DataFrame is large, we would not be able to observe it. isnull() provides a convenient way to check abnormal values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VSTRhb9boLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db8faff7-60c8-4fe2-98e6-64aceaae6f7b"
      },
      "source": [
        "missing = aapl_bar.isnull()\n",
        "print(missing)\n",
        "print('\\n------------------ separate line -----------------\\n')\n",
        "print(missing.describe())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             Open   High    Low  Close  rate_return\n",
            "Date                                               \n",
            "2016-01-31  False  False  False  False         True\n",
            "2016-02-29  False  False  False  False        False\n",
            "2016-03-31  False  False  False  False        False\n",
            "2016-04-30  False  False  False  False        False\n",
            "2016-05-31  False  False  False  False        False\n",
            "2016-06-30  False  False  False  False        False\n",
            "2016-07-31  False  False  False  False        False\n",
            "2016-08-31  False  False  False  False        False\n",
            "2016-09-30  False  False  False  False        False\n",
            "2016-10-31  False  False  False  False        False\n",
            "2016-11-30  False  False  False  False        False\n",
            "2016-12-31  False  False  False  False        False\n",
            "\n",
            "------------------ separate line -----------------\n",
            "\n",
            "         Open   High    Low  Close rate_return\n",
            "count      12     12     12     12          12\n",
            "unique      1      1      1      1           2\n",
            "top     False  False  False  False       False\n",
            "freq       12     12     12     12          11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSApoReGKFeW"
      },
      "source": [
        "The row labelled \"unique\" indicates the number of unique values in each column. Since the \"rate_return\" column has 2 unique values, it has at least one missing value.\n",
        "\n",
        "We can deduce the number of missing values by comparing \"count\" with \"freq\". There are 12 counts and 11 False values, so there is one True value which corresponds to the missing value.\n",
        "\n",
        "We can also find the rows with missing values easily:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZBH1VFIboLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a3356e-5424-4fe7-fafb-44f12614cf2c"
      },
      "source": [
        "print(missing[missing.rate_return == True])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             Open   High    Low  Close  rate_return\n",
            "Date                                               \n",
            "2016-01-31  False  False  False  False         True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCS5OfwnKHFF"
      },
      "source": [
        "Usually when dealing with missing data, we either delete the whole row or fill it with some value. As we introduced in the Series chapter, the same method dropna() and fillna() can be applied to a DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbNswKa5boLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df95c6ab-5c8e-404f-97f2-25886edc1cef"
      },
      "source": [
        "drop = aapl_bar.dropna()\n",
        "print(drop)\n",
        "print('\\n---------------------- separate line--------------------\\n')\n",
        "fill = aapl_bar.fillna(0)\n",
        "print(fill)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close  rate_return\n",
            "Date                                                     \n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n",
            "\n",
            "---------------------- separate line--------------------\n",
            "\n",
            "              Open      High     Low   Close  rate_return\n",
            "Date                                                     \n",
            "2016-01-31   94.79   97.3400   94.35   97.34     0.000000\n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxr_jlvGKJ46"
      },
      "source": [
        "**DataFrame Concat**\n",
        "\n",
        "We have seen how to extract a Series from a dataFrame. Now we need to consider how to merge a Series or a DataFrame into another one.\n",
        "\n",
        "In Pandas, the function concat() allows us to merge multiple Series into a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdX2V5umboLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451bc013-6ca2-4ace-dfaf-4b7f85020994"
      },
      "source": [
        "s1 = pd.Series([143.5, 144.09, 142.73, 144.18, 143.77], name = 'AAPL')\n",
        "s2 = pd.Series([898.7, 911.71, 906.69, 918.59, 926.99], name = 'GOOG')\n",
        "data_frame = pd.concat([s1,s2], axis = 1)\n",
        "print(data_frame)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     AAPL    GOOG\n",
            "0  143.50  898.70\n",
            "1  144.09  911.71\n",
            "2  142.73  906.69\n",
            "3  144.18  918.59\n",
            "4  143.77  926.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJKjwrk5KMqS"
      },
      "source": [
        "The \"axis = 1\" parameter will join two DataFrames by columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfhS2wttboLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffa6a9d6-cee8-4e01-e2cd-66c383ec587e"
      },
      "source": [
        "log_price = np.log(aapl_bar.Close)\n",
        "log_price.name = 'log_price'\n",
        "print(log_price)\n",
        "print('\\n---------------------- separate line--------------------\\n')\n",
        "concat = pd.concat([aapl_bar, log_price], axis = 1)\n",
        "print(concat)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Date\n",
            "2016-01-31    4.578210\n",
            "2016-02-29    4.571510\n",
            "2016-03-31    4.691256\n",
            "2016-04-30    4.540525\n",
            "2016-05-31    4.603769\n",
            "2016-06-30    4.560173\n",
            "2016-07-31    4.646408\n",
            "2016-08-31    4.664382\n",
            "2016-09-30    4.727830\n",
            "2016-10-31    4.732155\n",
            "2016-11-30    4.705197\n",
            "2016-12-31    4.752037\n",
            "Freq: M, Name: log_price, dtype: float64\n",
            "\n",
            "---------------------- separate line--------------------\n",
            "\n",
            "              Open      High     Low   Close  rate_return  log_price\n",
            "Date                                                                \n",
            "2016-01-31   94.79   97.3400   94.35   97.34          NaN   4.578210\n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678   4.571510\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211   4.691256\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921   4.540525\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287   4.603769\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660   4.560173\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063   4.646408\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136   4.664382\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504   4.727830\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334   4.732155\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599   4.705197\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955   4.752037\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiAphL0kKO8x"
      },
      "source": [
        "We can also join two DataFrames by rows. Consider these two DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1mf5-qBboLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6032762-8569-4395-85c5-6fcbdacddecb"
      },
      "source": [
        "df_volume = aapl_table.loc['2016-10':'2017-04',['Volume', 'Split Ratio']].resample('M').agg(lambda x: x[-1])\n",
        "print(df_volume)\n",
        "print('\\n---------------------- separate line--------------------\\n')\n",
        "df_2017 = aapl_table.loc['2016-10':'2017-04',['Open', 'High', 'Low', 'Close']].resample('M').agg(lambda x: x[-1])\n",
        "print(df_2017)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                Volume  Split Ratio\n",
            "Date                               \n",
            "2016-10-31  26419398.0          1.0\n",
            "2016-11-30  36162258.0          1.0\n",
            "2016-12-31  30586265.0          1.0\n",
            "2017-01-31  49200993.0          1.0\n",
            "2017-02-28  23482860.0          1.0\n",
            "2017-03-31  19661651.0          1.0\n",
            "2017-04-30  20247187.0          1.0\n",
            "\n",
            "---------------------- separate line--------------------\n",
            "\n",
            "              Open     High     Low   Close\n",
            "Date                                       \n",
            "2016-10-31  113.65  114.230  113.20  113.54\n",
            "2016-11-30  111.56  112.200  110.27  110.52\n",
            "2016-12-31  116.65  117.200  115.43  115.82\n",
            "2017-01-31  121.15  121.390  120.62  121.35\n",
            "2017-02-28  137.08  137.435  136.70  136.99\n",
            "2017-03-31  143.72  144.270  143.01  143.66\n",
            "2017-04-30  144.09  144.300  143.27  143.65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNui3HkAKQxA"
      },
      "source": [
        "Now we merge the DataFrames with our DataFrame 'aapl_bar'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPBe1QRcboLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59afc9b-093e-44c8-8aa1-e5f40c64c6b8"
      },
      "source": [
        "concat = pd.concat([aapl_bar,df_volume],axis = 1)\n",
        "print(concat)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low  ...  rate_return      Volume  Split Ratio\n",
            "Date                                  ...                                      \n",
            "2016-01-31   94.79   97.3400   94.35  ...          NaN         NaN          NaN\n",
            "2016-02-29   96.86   98.2300   96.65  ...    -0.006678         NaN          NaN\n",
            "2016-03-31  109.72  109.9000  108.88  ...     0.127211         NaN          NaN\n",
            "2016-04-30   93.99   94.7200   92.51  ...    -0.139921         NaN          NaN\n",
            "2016-05-31   99.60  100.4000   98.82  ...     0.065287         NaN          NaN\n",
            "2016-06-30   94.44   95.7700   94.30  ...    -0.042660         NaN          NaN\n",
            "2016-07-31  104.19  104.5500  103.68  ...     0.090063         NaN          NaN\n",
            "2016-08-31  105.66  106.5699  105.64  ...     0.018136         NaN          NaN\n",
            "2016-09-30  112.46  113.3700  111.80  ...     0.065504         NaN          NaN\n",
            "2016-10-31  113.65  114.2300  113.20  ...     0.004334  26419398.0          1.0\n",
            "2016-11-30  111.56  112.2000  110.27  ...    -0.026599  36162258.0          1.0\n",
            "2016-12-31  116.65  117.2000  115.43  ...     0.047955  30586265.0          1.0\n",
            "2017-01-31     NaN       NaN     NaN  ...          NaN  49200993.0          1.0\n",
            "2017-02-28     NaN       NaN     NaN  ...          NaN  23482860.0          1.0\n",
            "2017-03-31     NaN       NaN     NaN  ...          NaN  19661651.0          1.0\n",
            "2017-04-30     NaN       NaN     NaN  ...          NaN  20247187.0          1.0\n",
            "\n",
            "[16 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCjIWC8AKWDF"
      },
      "source": [
        "By default the DataFrame are joined with all of the data. This default options results in zero information loss. We can also merge them by intersection, this is called 'inner join':"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyA5rhzEboLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96165d37-b2ab-4401-8942-e4a0017db17d"
      },
      "source": [
        "concat = pd.concat([aapl_bar,df_volume],axis = 1, join = 'inner')\n",
        "print(concat)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open    High     Low  ...  rate_return      Volume  Split Ratio\n",
            "Date                                ...                                      \n",
            "2016-10-31  113.65  114.23  113.20  ...     0.004334  26419398.0          1.0\n",
            "2016-11-30  111.56  112.20  110.27  ...    -0.026599  36162258.0          1.0\n",
            "2016-12-31  116.65  117.20  115.43  ...     0.047955  30586265.0          1.0\n",
            "\n",
            "[3 rows x 7 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiik-gunKXXR"
      },
      "source": [
        "Only the intersection part was left if use 'inner join' method. Now let's try to append a DataFrame to another one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMpBnTnMboLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60a1b579-0849-4ad0-8073-ee8b44f8ac84"
      },
      "source": [
        "append = aapl_bar.append(df_2017)\n",
        "print(append)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close  rate_return\n",
            "Date                                                     \n",
            "2016-01-31   94.79   97.3400   94.35   97.34          NaN\n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n",
            "2016-10-31  113.65  114.2300  113.20  113.54          NaN\n",
            "2016-11-30  111.56  112.2000  110.27  110.52          NaN\n",
            "2016-12-31  116.65  117.2000  115.43  115.82          NaN\n",
            "2017-01-31  121.15  121.3900  120.62  121.35          NaN\n",
            "2017-02-28  137.08  137.4350  136.70  136.99          NaN\n",
            "2017-03-31  143.72  144.2700  143.01  143.66          NaN\n",
            "2017-04-30  144.09  144.3000  143.27  143.65          NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQvWzVepKZAn"
      },
      "source": [
        "'Append' is essentially to concat two DataFrames by axis = 0, thus here is an alternative way to append:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U5sxyZoboLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f2f0fe-6fa9-4256-cce3-1f60cddd0a26"
      },
      "source": [
        "concat = pd.concat([aapl_bar, df_2017], axis = 0)\n",
        "print(concat)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close  rate_return\n",
            "Date                                                     \n",
            "2016-01-31   94.79   97.3400   94.35   97.34          NaN\n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955\n",
            "2016-10-31  113.65  114.2300  113.20  113.54          NaN\n",
            "2016-11-30  111.56  112.2000  110.27  110.52          NaN\n",
            "2016-12-31  116.65  117.2000  115.43  115.82          NaN\n",
            "2017-01-31  121.15  121.3900  120.62  121.35          NaN\n",
            "2017-02-28  137.08  137.4350  136.70  136.99          NaN\n",
            "2017-03-31  143.72  144.2700  143.01  143.66          NaN\n",
            "2017-04-30  144.09  144.3000  143.27  143.65          NaN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxZFmlkSKafj"
      },
      "source": [
        "Please note that if the two DataFrame have some columns with the same column names, these columns are considered to be the same and will be merged. It's very important to have the right column names. If we change a column names here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L5AI8-HboLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ad56c4-8c6d-438d-b041-3d8504fe5e0d"
      },
      "source": [
        "df_2017.columns = ['Change', 'High','Low','Close']\n",
        "concat = pd.concat([aapl_bar, df_2017], axis = 0)\n",
        "print(concat)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close  rate_return  Change\n",
            "Date                                                             \n",
            "2016-01-31   94.79   97.3400   94.35   97.34          NaN     NaN\n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678     NaN\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211     NaN\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921     NaN\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287     NaN\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660     NaN\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063     NaN\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136     NaN\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504     NaN\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334     NaN\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599     NaN\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955     NaN\n",
            "2016-10-31     NaN  114.2300  113.20  113.54          NaN  113.65\n",
            "2016-11-30     NaN  112.2000  110.27  110.52          NaN  111.56\n",
            "2016-12-31     NaN  117.2000  115.43  115.82          NaN  116.65\n",
            "2017-01-31     NaN  121.3900  120.62  121.35          NaN  121.15\n",
            "2017-02-28     NaN  137.4350  136.70  136.99          NaN  137.08\n",
            "2017-03-31     NaN  144.2700  143.01  143.66          NaN  143.72\n",
            "2017-04-30     NaN  144.3000  143.27  143.65          NaN  144.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvZUzSfsboLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d37090-3424-43a2-f961-09acf5ecb30a"
      },
      "source": [
        "concat = pd.concat([aapl_bar, df_2017], axis = 0)\n",
        "print(concat)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              Open      High     Low   Close  rate_return  Change\n",
            "Date                                                             \n",
            "2016-01-31   94.79   97.3400   94.35   97.34          NaN     NaN\n",
            "2016-02-29   96.86   98.2300   96.65   96.69    -0.006678     NaN\n",
            "2016-03-31  109.72  109.9000  108.88  108.99     0.127211     NaN\n",
            "2016-04-30   93.99   94.7200   92.51   93.74    -0.139921     NaN\n",
            "2016-05-31   99.60  100.4000   98.82   99.86     0.065287     NaN\n",
            "2016-06-30   94.44   95.7700   94.30   95.60    -0.042660     NaN\n",
            "2016-07-31  104.19  104.5500  103.68  104.21     0.090063     NaN\n",
            "2016-08-31  105.66  106.5699  105.64  106.10     0.018136     NaN\n",
            "2016-09-30  112.46  113.3700  111.80  113.05     0.065504     NaN\n",
            "2016-10-31  113.65  114.2300  113.20  113.54     0.004334     NaN\n",
            "2016-11-30  111.56  112.2000  110.27  110.52    -0.026599     NaN\n",
            "2016-12-31  116.65  117.2000  115.43  115.82     0.047955     NaN\n",
            "2016-10-31     NaN  114.2300  113.20  113.54          NaN  113.65\n",
            "2016-11-30     NaN  112.2000  110.27  110.52          NaN  111.56\n",
            "2016-12-31     NaN  117.2000  115.43  115.82          NaN  116.65\n",
            "2017-01-31     NaN  121.3900  120.62  121.35          NaN  121.15\n",
            "2017-02-28     NaN  137.4350  136.70  136.99          NaN  137.08\n",
            "2017-03-31     NaN  144.2700  143.01  143.66          NaN  143.72\n",
            "2017-04-30     NaN  144.3000  143.27  143.65          NaN  144.09\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFY9ToeJKcxC"
      },
      "source": [
        "Since the column name of 'Open' has been changed, the new DataFrame has an new column named 'Change'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwwSryoqKePj"
      },
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af1ZU2lZKjsC"
      },
      "source": [
        "\n",
        "Hereby we introduced the most import part of python: resampling and DataFrame manipulation. We only introduced the most commonly used method in Financial data analysis. There are also many methods used in data mining, which are also beneficial. You can always check the Pandas official documentations for help."
      ]
    }
  ]
}